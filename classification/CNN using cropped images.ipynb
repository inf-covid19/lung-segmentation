{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Convolution2D\n",
    "    from keras.layers import MaxPooling2D\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Dense\n",
    "    from keras import models\n",
    "    from keras import optimizers\n",
    "    from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "    from keras import applications\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "TRAIN_IMG_SRC_FOLDER = '/home/chicobentojr/Desktop/L3Net_exames_segmentados'\n",
    "TRAIN_IMG_FOLDERS = {\n",
    "    \"exame1\": \"healthy\",\n",
    "    \"exame2\": \"healthy\",\n",
    "    \"exame3\": \"healthy\",\n",
    "    \"exame4\": \"healthy\",\n",
    "    \"exame11\": \"not healthy\",\n",
    "    \"exame12\": \"not healthy\",\n",
    "    \"exame13\": \"not healthy\",\n",
    "    \"exame14\": \"not healthy\",\n",
    "}\n",
    "\n",
    "TEST_IMG_SRC_FOLDER = '/home/chicobentojr/Desktop/L3Net_exames_segmentados'\n",
    "TEST_IMG_FOLDERS = {\n",
    "    \"exame5\": \"healthy\",\n",
    "    \"exame15\": \"not healthy\",\n",
    "}\n",
    "\n",
    "EXAM_SLICE = 200\n",
    "CLASSES = len(set([label for label in TRAIN_IMG_FOLDERS.values()]))\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train fold with 1600 images\nlabel\nhealthy        800\nnot healthy    800\nName: label, dtype: int64\n\nTest fold with 400 images\nlabel\nhealthy        200\nnot healthy    200\nName: label, dtype: int64\n------------------------------\n"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "train_images = {\"id\": [], \"label\": []}\n",
    "test_images = {\"id\": [], \"label\": []}\n",
    "\n",
    "df_config = [\n",
    "    (TRAIN_IMG_SRC_FOLDER, TRAIN_IMG_FOLDERS, train_images),\n",
    "    (TEST_IMG_SRC_FOLDER, TEST_IMG_FOLDERS, test_images)\n",
    "]\n",
    "\n",
    "\n",
    "def get_filespath(folder, search_filter=''):\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            if search_filter in path:\n",
    "                paths.append(path)\n",
    "    return paths\n",
    "\n",
    "\n",
    "for (base, folder, dic) in df_config:\n",
    "    for img_folder, img_label in folder.items():\n",
    "        search_folder = \"{}/{}\".format(base, img_folder)\n",
    "        imgs_filename = sorted(get_filespath(search_folder, search_filter='images'))[EXAM_SLICE:EXAM_SLICE*2]\n",
    "        dic[\"id\"].extend(imgs_filename)\n",
    "        dic[\"label\"].extend([img_label] * len(imgs_filename))\n",
    "\n",
    "    dfs.append(pd.DataFrame(data=dic))\n",
    "\n",
    "train_df, test_df = dfs[0], dfs[1]\n",
    "\n",
    "train_df.to_csv('train_df.csv', index=False)\n",
    "test_df.to_csv('test_df.csv', index=False)\n",
    "\n",
    "print(\"Train fold with {} images\".format(len(train_df)))\n",
    "print(train_df.groupby(\"label\").label.count())\n",
    "print()\n",
    "print(\"Test fold with {} images\".format(len(test_df)))\n",
    "print(test_df.groupby(\"label\").label.count())\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(dataframe, x_col, y_col, subset=None, shuffle=True):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1)\n",
    "\n",
    "    \n",
    "    data_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col=x_col,\n",
    "        y_col=y_col,\n",
    "        subset=subset,\n",
    "        target_size=(64, 64),\n",
    "        class_mode=\"binary\",\n",
    "        # color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #initializing the CNN\n",
    "    classifier= Sequential()\n",
    "    #Step 1- adding the Convolutional Layer\n",
    "    classifier.add(Convolution2D(32, (3, 3), input_shape= (64,64,3), activation= 'relu'))\n",
    "    #Step 2- adding MaxPooling Layer\n",
    "    classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "    #Step 3- Flattening\n",
    "    classifier.add(Flatten())\n",
    "    #Step 4- Classic ANN with fully-connected layers\n",
    "    classifier.add(Dense(activation=\"relu\", units=128))\n",
    "    classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "    return classifier\n",
    "\n",
    "def train_model(model, train_df, test_df, epochs, callbacks=[]):\n",
    "    train_generator = get_data_generator(train_df, \"id\", \"label\")\n",
    "    validation_generator = get_data_generator(test_df, \"id\", \"label\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    step_size_train = train_generator.n // train_generator.batch_size\n",
    "    step_size_validation = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "    if step_size_train == 0:\n",
    "        step_size_train = train_generator.n // 2\n",
    "        step_size_validation = validation_generator.n // 2\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=step_size_validation,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    return history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 1600 validated image filenames belonging to 2 classes.\nFound 400 validated image filenames belonging to 2 classes.\nWARNING:tensorflow:From /home/chicobentojr/.local/share/virtualenvs/lung-segmentation-Ojs2-P35/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n50/50 [==============================] - 12s 244ms/step - loss: 0.5407 - acc: 0.7463 - val_loss: 0.6507 - val_acc: 0.7005\nEpoch 2/10\n50/50 [==============================] - 10s 200ms/step - loss: 0.4334 - acc: 0.8056 - val_loss: 0.6677 - val_acc: 0.6685\nEpoch 3/10\n50/50 [==============================] - 10s 204ms/step - loss: 0.3685 - acc: 0.8344 - val_loss: 0.9076 - val_acc: 0.5190\nEpoch 4/10\n50/50 [==============================] - 10s 206ms/step - loss: 0.3085 - acc: 0.8731 - val_loss: 0.7950 - val_acc: 0.5272\nEpoch 5/10\n50/50 [==============================] - 11s 220ms/step - loss: 0.2897 - acc: 0.8794 - val_loss: 0.7775 - val_acc: 0.6495\nEpoch 6/10\n50/50 [==============================] - 11s 213ms/step - loss: 0.2562 - acc: 0.9019 - val_loss: 0.9999 - val_acc: 0.4348\nEpoch 7/10\n50/50 [==============================] - 11s 211ms/step - loss: 0.2145 - acc: 0.9219 - val_loss: 1.1465 - val_acc: 0.4402\nEpoch 8/10\n50/50 [==============================] - 10s 209ms/step - loss: 0.1958 - acc: 0.9200 - val_loss: 1.1783 - val_acc: 0.4076\nEpoch 9/10\n50/50 [==============================] - 11s 215ms/step - loss: 0.1662 - acc: 0.9381 - val_loss: 1.4078 - val_acc: 0.3859\nEpoch 10/10\n50/50 [==============================] - 11s 213ms/step - loss: 0.1890 - acc: 0.9287 - val_loss: 1.1612 - val_acc: 0.4103\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'val_loss': [0.6507291893164316,\n  0.6677262083343838,\n  0.9075606672660165,\n  0.7949829853099325,\n  0.7774807059246561,\n  0.999906793884609,\n  1.1465244707853899,\n  1.1783193608988887,\n  1.4077583966047869,\n  1.1612184462339983],\n 'val_acc': [0.7005208333333334,\n  0.6684782608695652,\n  0.5190217391304348,\n  0.5271739130434783,\n  0.6494565217391305,\n  0.43478260869565216,\n  0.44021739130434784,\n  0.4076086956521739,\n  0.3858695652173913,\n  0.41032608695652173],\n 'loss': [0.5407426702976227,\n  0.43337304711341856,\n  0.3684548878669739,\n  0.30852124333381653,\n  0.28967876940965653,\n  0.25617605477571487,\n  0.2144882644712925,\n  0.19582326889038085,\n  0.1661972899734974,\n  0.18899537086486817],\n 'acc': [0.74625,\n  0.805625,\n  0.834375,\n  0.873125,\n  0.879375,\n  0.901875,\n  0.921875,\n  0.92,\n  0.938125,\n  0.92875]}"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "history = train_model(model, train_df, test_df, EPOCHS)\n",
    "\n",
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('lung-segmentation': pipenv)",
   "language": "python",
   "name": "python37664bitlungsegmentationpipenv0a29b5972e9240148d6c76f5c065deba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}