{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras import applications\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = \"./train\"\n",
    "train_file_names = os.listdir(train_folder_path)\n",
    "random.shuffle(train_file_names)\n",
    "\n",
    "test_folder_path = \"./test\"\n",
    "test_file_names = os.listdir(test_folder_path)\n",
    "random.shuffle(test_file_names)\n",
    "\n",
    "width = 64\n",
    "height = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = list()\n",
    "train_full_paths = list()\n",
    "for file_name in train_file_names:\n",
    "        target = file_name[0]\n",
    "        full_path = os.path.join(train_folder_path, file_name)\n",
    "        train_full_paths.append(full_path)\n",
    "        train_targets.append(target)\n",
    "        \n",
    "train_set = pd.DataFrame()\n",
    "train_set['image_path'] = train_full_paths\n",
    "train_set['target'] = train_targets\n",
    "\n",
    "test_targets = list()\n",
    "test_full_paths = list()\n",
    "for file_name in test_file_names:\n",
    "        target = file_name[0]\n",
    "        full_path = os.path.join(test_folder_path, file_name)\n",
    "        test_full_paths.append(full_path)\n",
    "        test_targets.append(target)\n",
    "        \n",
    "test_set = pd.DataFrame()\n",
    "test_set['image_path'] = test_full_paths\n",
    "test_set['target'] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train/h_091815.603070_I3200001.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train/o_210836.851914_I9000001.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train/o_132446.967902_I4000001.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train/o_132451.517022_I3900001.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train/o_132449.006877_I1970000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./train/o_132449.765191_I2550000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./train/o_132450.333726_I2980000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./train/h_091808.634288_I9800000.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./train/o_205844.573332_I1150000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./train/o_210828.929527_I3420000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image_path target\n",
       "0  ./train/h_091815.603070_I3200001.png      h\n",
       "1  ./train/o_210836.851914_I9000001.png      o\n",
       "2  ./train/o_132446.967902_I4000001.png      o\n",
       "3  ./train/o_132451.517022_I3900001.png      o\n",
       "4  ./train/o_132449.006877_I1970000.png      o\n",
       "5  ./train/o_132449.765191_I2550000.png      o\n",
       "6  ./train/o_132450.333726_I2980000.png      o\n",
       "7  ./train/h_091808.634288_I9800000.png      h\n",
       "8  ./train/o_205844.573332_I1150000.png      o\n",
       "9  ./train/o_210828.929527_I3420000.png      o"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./test/o_170710.053686_I1040000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./test/o_170713.202492_I2050000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./test/h_144927.826281_I2770000.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./test/h_144933.595914_I4610000.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./test/o_170717.292069_I3350000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./test/o_170716.497706_I3090000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./test/h_144927.906305_I2800001.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./test/o_170707.135295_I1100000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./test/o_170720.263326_I4300001.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./test/o_170716.093685_I2970000.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path target\n",
       "0  ./test/o_170710.053686_I1040000.png      o\n",
       "1  ./test/o_170713.202492_I2050000.png      o\n",
       "2  ./test/h_144927.826281_I2770000.png      h\n",
       "3  ./test/h_144933.595914_I4610000.png      h\n",
       "4  ./test/o_170717.292069_I3350000.png      o\n",
       "5  ./test/o_170716.497706_I3090000.png      o\n",
       "6  ./test/h_144927.906305_I2800001.png      h\n",
       "7  ./test/o_170707.135295_I1100000.png      o\n",
       "8  ./test/o_170720.263326_I4300001.png      o\n",
       "9  ./test/o_170716.093685_I2970000.png      o"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy patients in the training set:800\n",
      "Number of non-healthy patients in the training set:800\n"
     ]
    }
   ],
   "source": [
    "target_counts=train_set['target'].value_counts()\n",
    "print(\"Number of healthy patients in the training set:{}\".format(target_counts['h']))\n",
    "print(\"Number of non-healthy patients in the training set:{}\".format(target_counts['o']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy patients in the test set:200\n",
      "Number of non-healthy patients in the test set:200\n"
     ]
    }
   ],
   "source": [
    "target_counts=test_set['target'].value_counts()\n",
    "print(\"Number of healthy patients in the test set:{}\".format(target_counts['h']))\n",
    "print(\"Number of non-healthy patients in the test set:{}\".format(target_counts['o']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the CNN\n",
    "classifier= Sequential()\n",
    "#Step 1- adding the Convolutional Layer\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape= (64,64,3), activation= 'relu'))\n",
    "#Step 2- adding MaxPooling Layer\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "#Step 3- Flattening\n",
    "classifier.add(Flatten())\n",
    "#Step 4- Classic ANN with fully-connected layers\n",
    "classifier.add(Dense(activation=\"relu\", units=128))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the whole model\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "rotation_range=15,\n",
    "rescale=1./255,\n",
    "shear_range=0.1,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1)\n",
    "\n",
    "train_datagenerator=train_datagen.flow_from_dataframe(dataframe=train_set,\n",
    "                                                     x_col=\"image_path\",\n",
    "                                                     y_col=\"target\",\n",
    "                                                     target_size=(width, height),\n",
    "                                                     class_mode=\"binary\",\n",
    "                                                     batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator=test_datagen.flow_from_dataframe(dataframe=test_set,\n",
    "                                                   x_col=\"image_path\",\n",
    "                                                   y_col=\"target\",\n",
    "                                                   target_size=(width, height),\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 1728s 1s/step - loss: 0.1198 - accuracy: 0.9537 - val_loss: 0.7895 - val_accuracy: 0.7474\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 1639s 1s/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 1.1873 - val_accuracy: 0.7101\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 1617s 1s/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 1.0217 - val_accuracy: 0.7399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58b8355340>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_datagenerator,\n",
    "                         steps_per_epoch = 1600,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_datagenerator,\n",
    "                         validation_steps = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a CNN with more layers\n",
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(64, (3, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Convolution2D(128, (3, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units= 512, activation= 'relu'))\n",
    "\n",
    "classifier.add(Dense(units= 1, activation= 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer= 'adam', loss= 'binary_crossentropy' ,metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 validated image filenames belonging to 2 classes.\n",
      "Found 400 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/6\n",
      "1600/1600 [==============================] - 377s 235ms/step - loss: 0.1048 - accuracy: 0.9542 - val_loss: 0.2211 - val_accuracy: 0.9575\n",
      "Epoch 2/6\n",
      "1600/1600 [==============================] - 356s 222ms/step - loss: 0.0183 - accuracy: 0.9934 - val_loss: 0.5453 - val_accuracy: 0.9050\n",
      "Epoch 3/6\n",
      "1600/1600 [==============================] - 357s 223ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.1593 - val_accuracy: 0.9601\n",
      "Epoch 4/6\n",
      "1600/1600 [==============================] - 358s 223ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.2716 - val_accuracy: 0.9328\n",
      "Epoch 5/6\n",
      "1600/1600 [==============================] - 358s 224ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.1572 - val_accuracy: 0.9526\n",
      "Epoch 6/6\n",
      "1600/1600 [==============================] - 359s 224ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.2773 - val_accuracy: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5850457d60>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "rotation_range=15,\n",
    "rescale=1./255,\n",
    "shear_range=0.1,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=False,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1)\n",
    "\n",
    "train_datagenerator=train_datagen.flow_from_dataframe(dataframe=train_set,\n",
    "                                                     x_col=\"image_path\",\n",
    "                                                     y_col=\"target\",\n",
    "                                                     target_size=(width, height),\n",
    "                                                     class_mode=\"binary\",\n",
    "                                                     batch_size=32)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator=test_datagen.flow_from_dataframe(dataframe=test_set,\n",
    "                                                   x_col=\"image_path\",\n",
    "                                                   y_col=\"target\",\n",
    "                                                   target_size=(width, height),\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   batch_size=32)\n",
    "\n",
    "classifier.fit(train_datagenerator,\n",
    "                         steps_per_epoch = 1600,\n",
    "                         epochs = 6,\n",
    "                         validation_data = test_datagenerator,\n",
    "                         validation_steps = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
